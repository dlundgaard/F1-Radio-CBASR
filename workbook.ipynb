{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d257b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import librosa\n",
    "import jiwer\n",
    "import warnings\n",
    "import whisper.normalizers\n",
    "import ptitprince as pt\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import (\n",
    "    pyplot as plt,\n",
    "    ticker,\n",
    ")\n",
    "\n",
    "plt.style.use(\"assets/minimal.mplstyle\")\n",
    "plt.rcParams[\"figure.dpi\"] = 300\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    category=FutureWarning,\n",
    ")\n",
    "\n",
    "class COLORMAP:\n",
    "    F1_red = \"#E10600\"\n",
    "\n",
    "audio_files_path = Path() / \"data\" / \"audio_clips\"\n",
    "text_normalizer = whisper.normalizers.EnglishTextNormalizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbeec35",
   "metadata": {},
   "source": [
    "- ALEALB01_23_20240229_154846 optics > upshift\n",
    "- LANNOR01_4_20250419_205244 im an f'ing idiot\n",
    "- MAXVER01_1_20250413_181201 lado > lando\n",
    "- LANNOR01_4_20240824_122457 landon > lando\n",
    "- LANNOR01_4_20250906_163307 map > lap\n",
    "- LANNOR01_4_20241201_113249 can't hear your â€“ strat 10!!!\n",
    "- MAXVER01_1_20251109_152028 deck > deg(radation)\n",
    "- ANDANT01_12_20250316_170136 [silence gets transcribed as \"thank you\"] \n",
    "- LIALAW01_30_20250615_151510 peel > PU\n",
    "- GUAZHO01_24_20240706_113306 upship > upshift\n",
    "- LANNOR01_4_20240405_034437 landau > Lando\n",
    "- LANNOR01_4_20240302_153321 lina > Lando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3261a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(url):\n",
    "    return requests.get(url).json()\n",
    "\n",
    "radio_messages = pd.merge(\n",
    "    left=pd.DataFrame.from_records(get_json(\"https://api.openf1.org/v1/team_radio\")),\n",
    "    right=pd.DataFrame.from_records(get_json(\"https://api.openf1.org/v1/sessions\"))[[\n",
    "        \"session_key\",\n",
    "        \"location\",\n",
    "        \"year\",\n",
    "        \"session_name\",\n",
    "    ]],\n",
    "    on=\"session_key\",\n",
    "    how=\"left\",\n",
    ").rename(columns=dict(\n",
    "    date=\"timestamp\",\n",
    ")).astype(dict(\n",
    "    timestamp=\"datetime64[ns, UTC]\",\n",
    ")).sort_values(\"timestamp\")\n",
    "\n",
    "radio_messages[\"identifier\"] = radio_messages[\"recording_url\"].str.split(\"/\").str[-1]\n",
    "radio_messages[\"file_path\"] = (audio_files_path / radio_messages[\"identifier\"]).astype(str)\n",
    "\n",
    "print(f\"Found {len(radio_messages)} radio messages across {radio_messages[\"session_key\"].nunique()} sessions over {radio_messages[\"meeting_key\"].nunique()} Formula 1 events from {radio_messages[\"timestamp\"].iloc[0].date()} to {radio_messages[\"timestamp\"].iloc[-1].date()}\")\n",
    "radio_messages.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8039f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_duration(file_path):\n",
    "    try:\n",
    "        return librosa.get_duration(path=file_path)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "if not \"clip_duration\" in radio_messages.columns:\n",
    "    radio_messages[\"clip_duration\"] = radio_messages[\"file_path\"].apply(get_clip_duration)\n",
    "    # radio_messages = radio_messages[radio_messages[\"clip_duration\"] < 30]\n",
    "\n",
    "print(f\"Total duration of all {len(radio_messages)} radio messages: {radio_messages[\"clip_duration\"].sum() / 60 / 60:.0f} hours\")\n",
    "\n",
    "plt.hist(\n",
    "    radio_messages[\"clip_duration\"],\n",
    "    bins=np.arange(0, 45, 0.5),\n",
    "    color=COLORMAP.F1_red,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1,\n",
    ")\n",
    "plt.axvline(\n",
    "    x=radio_messages[\"clip_duration\"].mean(),\n",
    "    color=\"silver\",\n",
    "    linestyle=\"dotted\",\n",
    "    label=f\"Mean {radio_messages[\"clip_duration\"].mean():.1f} sec\",\n",
    ")\n",
    "plt.axvline(\n",
    "    x=radio_messages[\"clip_duration\"].median(),\n",
    "    color=\"silver\",\n",
    "    linestyle=\"dashed\",\n",
    "    label=f\"Median {radio_messages[\"clip_duration\"].median():.1f} sec\",\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Audio clip duration [sec]\")\n",
    "plt.ylabel(\"Occurences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea28d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_audiofiles(file_path_todo_list):\n",
    "    for _, radio_message in tqdm(list(file_path_todo_list), smoothing=0):\n",
    "        if not Path(radio_message[\"file_path\"]).exists():\n",
    "            try:\n",
    "                with open(radio_message[\"file_path\"], mode=\"wb\") as file:\n",
    "                    file.write(requests.get(radio_message[\"recording_url\"]).content)\n",
    "            except:\n",
    "                print(\"Failed on\", radio_message[\"file_path\"])\n",
    "\n",
    "cache_audiofiles(\n",
    "    file_path_todo_list=radio_messages[~radio_messages[\"file_path\"].apply(Path).apply(Path.exists)][[\"recording_url\", \"file_path\"]].iloc[::-1].iterrows(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c994413",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5790a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_labeling_export = pd.read_json(sorted(Path(\"label-studio/export\").iterdir())[-1]).rename(columns=dict(\n",
    "    transcription=\"human_transcription\",\n",
    ")).drop_duplicates(\n",
    "    subset=\"identifier\",\n",
    "    keep=\"last\",\n",
    ")\n",
    "\n",
    "with_human_reference = pd.merge(\n",
    "    left=radio_messages,\n",
    "    right=human_labeling_export[[\n",
    "        \"identifier\",\n",
    "        \"human_transcription\",\n",
    "        \"lead_time\",\n",
    "        \"updated_at\",\n",
    "    ]].rename(columns=dict(updated_at=\"human_transcription_timestamp\")),\n",
    "    on=\"identifier\",\n",
    "    how=\"right\",\n",
    ")\n",
    "\n",
    "with_human_reference = with_human_reference[~with_human_reference[\"human_transcription\"].isna()]\n",
    "\n",
    "with_human_reference[[\n",
    "    \"identifier\",\n",
    "    \"file_path\",\n",
    "    \"human_transcription\",\n",
    "]].to_json(\n",
    "    \"data/with_human_reference.json\", \n",
    "    index=False,\n",
    "    orient=\"records\",\n",
    ")\n",
    "\n",
    "print(f\"Found {len(with_human_reference.drop_duplicates(subset=\"identifier\"))} radio message clips with human reference, total duration {with_human_reference[\"clip_duration\"].sum() / 60:.0f} minutes\")\n",
    "with_human_reference.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc573748",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee51f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_transcriptions = pd.read_csv(\n",
    "    \"exports/transcriptions.tsv\", \n",
    "    delimiter=\"\\t\",\n",
    "    names=(\n",
    "        \"transcription_timestamp\",\n",
    "        \"identifier\",\n",
    "        \"modelidentifier\",\n",
    "        \"machine_transcription\",\n",
    "        \"avg_logprob\",\n",
    "        \"text_nbest\",\n",
    "        \"no_speech_prob\",\n",
    "        \"temperature\",\n",
    "        \"compression_ratio\",\n",
    "        \"sum_logprob_nbest\",\n",
    "        \"token_nbest\",\n",
    "    ),\n",
    ").astype(dict(\n",
    "    transcription_timestamp=\"datetime64[ns, UTC]\",\n",
    "))\n",
    "\n",
    "machine_vs_human_transcriptions = pd.merge(\n",
    "    left=with_human_reference.drop(columns=[\n",
    "        \"meeting_key\",\n",
    "        \"session_key\",\n",
    "    ]),\n",
    "    right=machine_transcriptions,\n",
    "    on=\"identifier\",\n",
    "    how=\"left\",\n",
    ").sort_values(\"transcription_timestamp\").drop_duplicates(\n",
    "    subset=(\"identifier\", \"modelidentifier\"),\n",
    "    keep=\"first\",\n",
    ")\n",
    "machine_vs_human_transcriptions = machine_vs_human_transcriptions[~machine_vs_human_transcriptions[\"machine_transcription\"].isna()]\n",
    "\n",
    "print(f\"Found {len(machine_vs_human_transcriptions.drop_duplicates(subset=\"identifier\"))} machine transcribed radio messages that have human transcription, total duration {machine_vs_human_transcriptions.drop_duplicates(\"identifier\")[\"clip_duration\"].sum() / 60:.0f} minutes\")\n",
    "machine_vs_human_transcriptions.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e40a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_vs_human_transcriptions[[\"identifier\", \"modelidentifier\", \"machine_transcription\", \"human_transcription\"]].sort_values([\"identifier\", \"modelidentifier\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c7483",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617f5600",
   "metadata": {},
   "source": [
    "<!-- ln -s radio_messages/ /home/ucloud/.local/share/label-studio/radio_messages -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, estimator in [\n",
    "    (\"WER\", jiwer.wer),\n",
    "    (\"WIP\", jiwer.wip),\n",
    "]:\n",
    "    machine_vs_human_transcriptions[metric] = machine_vs_human_transcriptions.apply(lambda radio_message: estimator(\n",
    "        text_normalizer(radio_message[\"machine_transcription\"]),\n",
    "        text_normalizer(radio_message[\"human_transcription\"]),\n",
    "    ), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5309ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for metric in [\"WER\", \"WIP\"]:\n",
    "#     plt.hist(\n",
    "#         machine_vs_human_transcriptions[metric],\n",
    "#         bins=dict(\n",
    "#             wer=200,\n",
    "#             wip=np.linspace(0, 1, 100),\n",
    "#         )[metric],\n",
    "#         density=True,\n",
    "#         color=COLORMAP.F1_red,\n",
    "#         edgecolor=\"white\",\n",
    "#         linewidth=1,\n",
    "#     )\n",
    "#     plt.axvline(\n",
    "#         color=\"silver\",\n",
    "#         linestyle=\"dashed\",\n",
    "#     )\n",
    "#     plt.axvline(\n",
    "#         x=machine_vs_human_transcriptions[metric].mean(),\n",
    "#         color=\"silver\",\n",
    "#         linestyle=\"dotted\",\n",
    "#         label=f\"Mean {machine_vs_human_transcriptions[metric].mean():.1%}\",\n",
    "#     )\n",
    "#     plt.axvline(\n",
    "#         x=machine_vs_human_transcriptions[metric].median(),\n",
    "#         color=\"silver\",\n",
    "#         linestyle=\"dashed\",\n",
    "#         label=f\"Median {machine_vs_human_transcriptions[metric].median():.1%}\",\n",
    "#     )\n",
    "#     plt.legend(loc=\"upper right\")\n",
    "#     plt.xlabel(metric.upper())\n",
    "#     plt.ylabel(\"PMF\")\n",
    "#     if metric == \"WIP\":\n",
    "#         plt.xlim(0, 1)\n",
    "#     elif metric == \"WER\":\n",
    "#         plt.xlim(0, 3)\n",
    "#     plt.gca().xaxis.set_major_formatter(ticker.PercentFormatter(1))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2500f5b5",
   "metadata": {},
   "source": [
    "## WER stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16000fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_vs_human_transcriptions.groupby(\"modelidentifier\")[\"WER\"].describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaecc451",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_transcriptions = machine_vs_human_transcriptions[machine_vs_human_transcriptions[\"modelidentifier\"] == \"stockWhisper\"]\n",
    "TCPGen_transcriptions = machine_vs_human_transcriptions[machine_vs_human_transcriptions[\"modelidentifier\"] == \"TCPGenWhisper\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdfe2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(\n",
    "    stock_transcriptions[\"WER\"],\n",
    "    TCPGen_transcriptions[\"WER\"],\n",
    "    equal_var=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0109af",
   "metadata": {},
   "source": [
    "## WIP stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aad622",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_vs_human_transcriptions.groupby(\"modelidentifier\")[\"WIP\"].describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1cd2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(\n",
    "    stock_transcriptions[\"WIP\"],\n",
    "    TCPGen_transcriptions[\"WIP\"],\n",
    "    equal_var=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = pt.RainCloud(\n",
    "    data=machine_vs_human_transcriptions,\n",
    "    x=\"modelidentifier\",\n",
    "    y=\"WIP\",\n",
    "    hue=\"modelidentifier\",\n",
    "    bw=0.1,\n",
    "    palette=(\n",
    "        COLORMAP.F1_red,\n",
    "        \"grey\",\n",
    "    ),\n",
    "    width_viol=0.6,\n",
    "    width_box=0.2,\n",
    "    linewidth=0,\n",
    "    alpha=1,\n",
    "    point_size=2,\n",
    "    orient=\"h\",\n",
    "    rain_clip_on=False,\n",
    "    pointplot=True,\n",
    "    linecolor=\"black\",\n",
    "    point_linewidth=1.4,\n",
    "    point_errorbar=\"ci\",\n",
    "    point_errwidth=1.4,\n",
    "    point_capsize=0.05,\n",
    "    ax=ax, \n",
    ")\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"WIP\")\n",
    "plt.xlim(0, 1)\n",
    "plt.gca().xaxis.set_major_formatter(ticker.PercentFormatter(1))\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(Path() / \"exports\" / \"raincloud_plot_wip_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04542327",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/biasing_list.txt\") as file:\n",
    "    biasing_terms = [word.strip() for word in file]\n",
    "\n",
    "def biasing_terms_in_utterance(utterance):\n",
    "    words = [re.sub(r\"[^A-Za-z0-9 *]\", \"\", word).strip().upper() for word in utterance.upper().split()]\n",
    "    return list(set([word for word in words if word in biasing_terms]))\n",
    "\n",
    "machine_vs_human_transcriptions[\"biasing_terms\"] = machine_vs_human_transcriptions[\"human_transcription\"].apply(biasing_terms_in_utterance)\n",
    "\n",
    "machine_vs_human_transcriptions[machine_vs_human_transcriptions[\"biasing_terms\"].apply(len) > 0].groupby(\"modelidentifier\")[\"WIP\"].describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    machine_vs_human_transcriptions[\"biasing_terms\"].apply(len) / machine_vs_human_transcriptions[\"human_transcription\"].str.split().str.len(),\n",
    "    machine_vs_human_transcriptions[\"WIP\"],\n",
    "    color=COLORMAP.F1_red,\n",
    "    edgecolor=\"white\",\n",
    "    alpha=0.5,\n",
    "    clip_on=False,\n",
    "    zorder=5,\n",
    ")\n",
    "plt.gca().yaxis.set_major_formatter(ticker.PercentFormatter(1))\n",
    "plt.xscale(\"log\", base=10)\n",
    "plt.gca().xaxis.set_major_formatter(ticker.PercentFormatter(1))\n",
    "# plt.xlim(right=1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"Biasing terms proportion\")\n",
    "plt.ylabel(\"WIP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e148cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    machine_vs_human_transcriptions[\"clip_duration\"],\n",
    "    machine_vs_human_transcriptions[\"WIP\"],\n",
    "    color=COLORMAP.F1_red,\n",
    "    edgecolor=\"white\",\n",
    "    alpha=0.5,\n",
    "    clip_on=False,\n",
    "    zorder=5,\n",
    ")\n",
    "plt.gca().yaxis.set_major_formatter(ticker.PercentFormatter(1))\n",
    "plt.xscale(\"log\", base=10)\n",
    "plt.gca().xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"Clip duration [sec]\")\n",
    "plt.ylabel(\"WIP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(\n",
    "    machine_vs_human_transcriptions[\"human_transcription\"].str.split(\" \").str.len(),\n",
    "    machine_vs_human_transcriptions[\"machine_transcription\"].str.split(\" \").str.len(),\n",
    "    color=COLORMAP.F1_red,\n",
    "    edgecolor=\"white\",\n",
    "    alpha=0.5,\n",
    "    clip_on=False,\n",
    "    zorder=5,\n",
    ")\n",
    "plt.plot(\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    transform=plt.gca().transAxes,\n",
    "    color=\"silver\",\n",
    "    linestyle=\"dotted\",\n",
    "    zorder=-1,\n",
    ")\n",
    "plt.xscale(\"log\", base=10)\n",
    "plt.yscale(\"log\", base=10)\n",
    "plt.gca().xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "plt.gca().yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "plt.xlim(1, 150)\n",
    "plt.ylim(1, 150)\n",
    "plt.xlabel(\"Human transcription word count\")\n",
    "plt.ylabel(\"ASR transcription word count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bd056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_log = pd.read_csv(\n",
    "    sorted(Path(\"exports\").glob(\"log*\"))[-1],\n",
    "    names=(\n",
    "        \"timestamp\",\n",
    "        \"epoch\",\n",
    "        \"training_batch_loss\",\n",
    "        \"validation_batch_loss\",\n",
    "        \"model_accuracy\",\n",
    "    )\n",
    ")\n",
    "model_training_log\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for loss_type in (\n",
    "    \"training_loss\",\n",
    "    \"testing_loss\",\n",
    "):\n",
    "    plt.plot(\n",
    "        model_training_log[\"epoch\"],\n",
    "        model_training_log[loss_type],\n",
    "        label=f\"{loss_type.replace(\"_\", \" \").capitalize()}\",\n",
    "        marker=\"o\",\n",
    "        markerfacecolor=\"white\",\n",
    "        clip_on=False,\n",
    "        zorder=10,\n",
    "    )\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylim(bottom=0)\n",
    "plt.xlabel(\"Training epoch\")\n",
    "\n",
    "fig.savefig(Path() / \"exports\" / \"model_training_loss_curve.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95e96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -iv -v -m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_kernel",
   "language": "python",
   "name": "project_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
